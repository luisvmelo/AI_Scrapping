#!/usr/bin/env python3

import requests
from bs4 import BeautifulSoup
import time
import json
import re

def debug_aitools_advanced():
    """Advanced debugging of AITools Directory to find data sources"""
    
    session = requests.Session()
    session.headers.update({
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
        'Accept-Language': 'en-US,en;q=0.9',
        'Referer': 'https://aitoolsdirectory.com'
    })
    
    print("🔍 Advanced debugging of AITools Directory...")
    
    # Get main page and analyze all content
    print("\n=== FULL PAGE ANALYSIS ===")
    try:
        response = session.get("https://aitoolsdirectory.com", timeout=15)
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            
            print(f"Full HTML length: {len(response.text)} characters")
            print(f"HTML content preview:\n{response.text[:1000]}")
            
            # Look for any JavaScript that might contain API endpoints
            all_scripts = soup.find_all('script')
            print(f"\nFound {len(all_scripts)} script tags")
            
            for i, script in enumerate(all_scripts):
                if script.get('src'):
                    print(f"  Script {i}: External - {script.get('src')}")
                elif script.string:
                    content = script.string.strip()
                    if len(content) > 10:
                        print(f"  Script {i}: Inline - {content[:200]}...")
            
            # Look for any meta tags or config
            meta_tags = soup.find_all('meta')
            for meta in meta_tags:
                if meta.get('name') or meta.get('property'):
                    print(f"Meta: {meta.get('name') or meta.get('property')} = {meta.get('content', '')}")
    
    except Exception as e:
        print(f"Error in full page analysis: {e}")
    
    # Try different URL patterns that might have data
    print("\n=== TESTING DATA ENDPOINTS ===")
    potential_endpoints = [
        "https://aitoolsdirectory.com/data.json",
        "https://aitoolsdirectory.com/tools.json", 
        "https://aitoolsdirectory.com/api/tools.json",
        "https://aitoolsdirectory.com/api/data",
        "https://aitoolsdirectory.com/wp-json/wp/v2/posts",
        "https://aitoolsdirectory.com/feed",
        "https://aitoolsdirectory.com/sitemap.xml",
        "https://aitoolsdirectory.com/robots.txt"
    ]
    
    for url in potential_endpoints:
        try:
            resp = session.get(url, timeout=10)
            print(f"{url}: {resp.status_code}")
            if resp.status_code == 200:
                content_type = resp.headers.get('content-type', '')
                print(f"  Content-Type: {content_type}")
                if 'xml' in content_type or 'json' in content_type:
                    print(f"  Preview: {resp.text[:300]}")
        except Exception as e:
            print(f"{url}: ERROR - {e}")
    
    # Check if this is a static site generator or has a specific pattern
    print("\n=== CHECKING FOR STATIC SITE PATTERNS ===")
    try:
        # Check for common static site generator patterns
        response = session.get("https://aitoolsdirectory.com", timeout=15)
        content = response.text.lower()
        
        patterns = {
            'next.js': ['_next/', 'next.js', '__next'],
            'gatsby': ['gatsby', 'public/static'],
            'nuxt': ['nuxt', '_nuxt/'],
            'vue': ['vue.js', 'vue.min.js'],
            'react': ['react.js', 'react.min.js', 'reactdom'],
            'angular': ['angular.js', 'ng-'],
            'wordpress': ['wp-content', 'wp-includes'],
            'hugo': ['hugo', 'generated by hugo'],
            'jekyll': ['jekyll', 'generated by jekyll']
        }
        
        detected_frameworks = []
        for framework, keywords in patterns.items():
            if any(keyword in content for keyword in keywords):
                detected_frameworks.append(framework)
        
        print(f"Detected frameworks/patterns: {detected_frameworks or 'None detected'}")
        
        # Look for any data attributes or config variables
        data_patterns = [
            r'window\.__INITIAL_STATE__\s*=\s*({.*?});',
            r'window\.__DATA__\s*=\s*({.*?});',
            r'window\.app\s*=\s*({.*?});',
            r'var\s+data\s*=\s*({.*?});',
            r'const\s+data\s*=\s*({.*?});'
        ]
        
        for pattern in data_patterns:
            matches = re.findall(pattern, content, re.DOTALL)
            if matches:
                print(f"Found data pattern: {pattern}")
                for match in matches[:2]:  # Show first 2 matches
                    print(f"  Data: {match[:200]}...")
        
    except Exception as e:
        print(f"Error checking patterns: {e}")
    
    # Try to find any category or listing pages
    print("\n=== TESTING CATEGORY PAGES ===")
    category_urls = [
        "https://aitoolsdirectory.com/categories",
        "https://aitoolsdirectory.com/category/chatbots",
        "https://aitoolsdirectory.com/category/image-generation",
        "https://aitoolsdirectory.com/tools/page/1",
        "https://aitoolsdirectory.com/browse",
        "https://aitoolsdirectory.com/directory"
    ]
    
    for url in category_urls:
        try:
            resp = session.get(url, timeout=10)
            print(f"{url}: {resp.status_code}")
            if resp.status_code == 200:
                soup = BeautifulSoup(resp.text, 'html.parser')
                element_count = len(soup.find_all())
                print(f"  Total elements: {element_count}")
        except Exception as e:
            print(f"{url}: ERROR - {e}")

if __name__ == "__main__":
    debug_aitools_advanced()